{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a6d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gemini import rerank_with_gemini\n",
    "from openaimodel import rerank_with_openai\n",
    "\n",
    "# Load data\n",
    "items = pd.read_csv(\"cleaned_items_with_metadata.csv\")\n",
    "item_texts = items[\"full_text\"].tolist()\n",
    "queries = pd.read_csv(\"./data/queries.csv\")[\"search_term_pt\"].tolist()\n",
    "item_embeddings = np.load(\"./embeddings/text_embeddings_openai_small.npy\")\n",
    "query_embeddings = np.load(\"./embeddings/query_embeddings_openai_small.npy\")\n",
    " # Your precomputed 768-dim vector\n",
    "\n",
    "similarity_matrix = cosine_similarity(query_embeddings, item_embeddings)\n",
    "top_k = 8\n",
    "top_k_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66296cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i, item_idxs in enumerate(top_k_indices):\n",
    "    query_text = queries[i]\n",
    "    matched_items = [item_texts[j] for j in item_idxs]\n",
    "    results.append({\n",
    "        \"query\": query_text,\n",
    "        \"top_k_results\": matched_items\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b93e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Configure the Gemini client (OpenAI-compatible)\n",
    "client = OpenAI(api_key=\"XXXXXXXXXXXXX\")\n",
    "\n",
    "\n",
    "def evaluate_top3_with_llm(query, top3_items, model=\"gemini-1.5-pro-latest\"):\n",
    "    \"\"\"\n",
    "    Evaluates how relevant each item in top-3 is to the query using Gemini.\n",
    "    Returns 3 float scores (0–2) in original order.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a food search evaluator.\n",
    "\n",
    "Given a search query and three food item descriptions, rate how relevant each item is to the query on a scale from 0 to 2:\n",
    "- 2: Highly relevant (perfect match or very close)\n",
    "- 1: Somewhat relevant (partially matches or related)\n",
    "- 0: Not relevant (not matching or off-topic)\n",
    "\n",
    "Only output the scores as a comma-separated list, in order. No explanation.\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Items:\n",
    "1. {top3_items[0]}\n",
    "2. {top3_items[1]}\n",
    "3. {top3_items[2]}\n",
    "\n",
    "Output format: 2, 1, 0\n",
    "\"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    return response.output[0].content[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce2eed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 0, 1, 1\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "\n",
    "response = evaluate_top3_with_llm(queries[index], results[index][\"top_k_results\"])\n",
    "print(f\"Response: {response}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83c8410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scores: 0.0, 1.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "# get all 3 scores separtely and sum up on total\n",
    "\n",
    "scores = list(map(float, response.split(',')))\n",
    "total_n1 = scores[0]\n",
    "total_n2 = scores[1]\n",
    "total_n3 = scores[2]\n",
    "print(f\"Total scores: {total_n1}, {total_n2}, {total_n3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783ed94",
   "metadata": {},
   "source": [
    "## Evaluation without rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f067e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries: 100%|██████████| 100/100 [03:36<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Lanche reconfortante para a madrugada\n",
      "Top 3 items: [\"Lanche dona lurdes. Lanche de kafta com queijo, rucula maionese de alho e azeitonas pretas. Categoria: Lanches boquinha de anjo. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'SANDUICHES', 'l2': 'HAMBURGUERES'}\", \"Lanche de Linguiça Especial. Desfrute do nosso 'Lanche de Linguiça Especial', uma combinação perfeitamente harmonizada de linguiça saborosamente aberta, alface fresca e crocante, vinagrete suculento e apetitoso, cream cheese cremoso e indulgente, mussarela derretida e aconchegante, tudo envolvido em sua escolha de um pão francês crocante e dourado ou um pão de hambúrguer macio e esponjoso. Esta é a refeição perfeita para satisfazer a sua fome e despertar os seus sentidos. Uma delícia da categoria 'Lanches' que promete uma explosão de sabor a cada mordida!. Categoria: Lanches. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'SANDUICHES', 'l2': 'HAMBURGUERES'}\", \"Bebida Láctea Uht Chocolate com Café Frappuccino Starbucks 280ml. Categoria: Matinais. Taxonomia: {'l0': 'BEBIDAS', 'l1': 'BEBIDAS_LACTEAS_E_DE_SOJA', 'l2': 'ACHOCOLATADO'}\"]\n",
      "Scores: [2.0, 2.0, 0.0]\n",
      "Total scores: 118.0, 109.0, 79.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_n1 = 0\n",
    "total_n2 = 0\n",
    "total_n3 = 0\n",
    "for i, result in tqdm(enumerate(results), total=len(results), desc=\"Evaluating queries\"):\n",
    "    query = result[\"query\"]\n",
    "    top3_items = result[\"top_k_results\"]\n",
    "    \n",
    "    # Evaluate with LLM\n",
    "    response = evaluate_top3_with_llm(query, top3_items)\n",
    "    scores = list(map(float, response.split(',')))\n",
    "    \n",
    "    total_n1 += scores[0]\n",
    "    total_n2 += scores[1]\n",
    "    total_n3 += scores[2]\n",
    "    # Print results\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Top 3 items: {top3_items}\")\n",
    "print(f\"Scores: {scores}\")\n",
    "print(f\"Total scores: {total_n1}, {total_n2}, {total_n3}\")\n",
    "\n",
    "avg_n1 = total_n1 / len(results)\n",
    "avg_n2 = total_n2 / len(results)\n",
    "avg_n3 = total_n3 / len(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ea004",
   "metadata": {},
   "source": [
    "## Evaluation for rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01939ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating reranked queries: 100%|██████████| 100/100 [05:24<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query example: Lanche reconfortante para a madrugada\n",
      "Reranked items example: [\"Lanche de Linguiça Especial. Desfrute do nosso 'Lanche de Linguiça Especial', uma combinação perfeitamente harmonizada de linguiça saborosamente aberta, alface fresca e crocante, vinagrete suculento e apetitoso, cream cheese cremoso e indulgente, mussarela derretida e aconchegante, tudo envolvido em sua escolha de um pão francês crocante e dourado ou um pão de hambúrguer macio e esponjoso. Esta é a refeição perfeita para satisfazer a sua fome e despertar os seus sentidos. Uma delícia da categoria 'Lanches' que promete uma explosão de sabor a cada mordida!. Categoria: Lanches. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'SANDUICHES', 'l2': 'HAMBURGUERES'}\", \"Lanche dona lurdes. Lanche de kafta com queijo, rucula maionese de alho e azeitonas pretas. Categoria: Lanches boquinha de anjo. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'SANDUICHES', 'l2': 'HAMBURGUERES'}\", \"Copo da Felicidade Morango com Ninho e Nutella 300ml. Camadas irresistíveis de creme de Leite Ninho, morangos frescos e suculentos, e uma generosa porção de Nutella cremosa. Uma explosão de sabores em cada colherada, perfeita para adoçar seu Dia! \\n\\n\\n\\n\\n\\n-----------------tags-------------------\\nEntrega rápida , desconto , promoção , 0,99 , 0800 , off , cupom , barato , melhor preço , oferta , frete grátis , descontão , preço baixo , Doces , bolos , brigadeiro , docinhos , kit festa , aniversario , bolo de pote , chocolate , morango , sobremesa natalina , Nutella , copo da felicidade , brownie , confeitaria , doceria , gourmet , bombom , piscina , ganache , caseiro , vovó , bento cake , vulcão , red velvet , trufas , banoffe , pudim , doce de leite , pão de mel , Oreo , Kit Kat , ferrero Rocher , cheese cake , tartelete , Ninho , cupcake , afogadinho , bolo , Ninho , brigadeirão , mini , cascão , gourmet , cone\\xa0,\\xa0dois\\xa0amores. Categoria: Copo Da Felicidade Supreme. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'OUTROS', 'l2': 'OUTROS'}. Tags: SERVES_1\", \"Geladinho Gourmet Ninho com Nutella. Nosso  Geladinho  Ninho com Nutella  unindo a cremosidade do Leite Ninho e Nutella, resultado em uma experiência irresistível!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n-----tags---------\\nEntrega rápida , desconto , promoção , 0,99 , 0800 , off , cupom , barato , melhor preço , oferta , frete grátis , descontão , preço baixo , Doces , bolos , brigadeiro , docinhos , kit festa , aniversario , bolo de pote , chocolate , morango , sobremesa natalina , Nutella , copo da felicidade , brownie , confeitaria , doceria , gourmet , bombom , piscina , ganache , caseiro , vovó , bento cake , vulcão , red velvet , trufas , banoffe , pudim , doce de leite , pão de mel , Oreo , Kit Kat , ferrero Rocher , cheese cake , tartelete , Ninho , cupcake , afogadinho , bolo , Ninho , leite condensado, chocolatudo. Categoria: Geladinho Gourmet. Taxonomia: {'l0': 'ALIMENTOS_PREPARADOS', 'l1': 'OUTROS', 'l2': 'OUTROS'}. Tags: SERVES_1\", \"Bebida Láctea Uht Chocolate com Café Frappuccino Starbucks 280ml. Categoria: Matinais. Taxonomia: {'l0': 'BEBIDAS', 'l1': 'BEBIDAS_LACTEAS_E_DE_SOJA', 'l2': 'ACHOCOLATADO'}\", \"Bebida Láctea Uht Chocolate com Café Frappuccino Starbucks 280ml. Categoria: Matinais. Taxonomia: {'l0': 'BEBIDAS', 'l1': 'BEBIDAS_LACTEAS_E_DE_SOJA', 'l2': 'ACHOCOLATADO'}\", \"Café Solúvel Matinal Nescafé 100g. Vidro 100g. Categoria: Matinais. Taxonomia: {'l0': 'MERCEARIA', 'l1': 'CAFE_CHAS_ACHOCOLATADOS', 'l2': 'CAFE_SOLUVEL'}\", \"Café Fort 3 Corações Almofada 500g. Categoria: Matinais. Taxonomia: {'l0': 'MERCEARIA', 'l1': 'CAFE_CHAS_ACHOCOLATADOS', 'l2': 'CAFE_MOIDO'}\"]\n",
      "Scores example: [2.0, 2.0, 1.0]\n",
      "Total reranked scores: 158.0, 124.0, 77.0\n",
      "Average reranked scores: 1.58, 1.24, 0.77\n",
      "Baseline average scores: 1.18, 1.09, 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.openaimodel import rerank_with_openai\n",
    "\n",
    "total_n1_rerank = 0\n",
    "total_n2_rerank = 0\n",
    "total_n3_rerank = 0\n",
    "for i, result in tqdm(enumerate(results), total=len(results), desc=\"Evaluating reranked queries\"):\n",
    "    query = result[\"query\"]\n",
    "    top3_items = result[\"top_k_results\"]\n",
    "    new_rank = rerank_with_openai(query, top3_items)\n",
    "    reranked_items = [top3_items[int(i)-1] for i in new_rank.split(\",\")]\n",
    "    \n",
    "    # Evaluate with LLM\n",
    "    response = evaluate_top3_with_llm(query, reranked_items)\n",
    "    \n",
    "    scores = list(map(float, response.split(',')))\n",
    "    \n",
    "    total_n1_rerank += scores[0]\n",
    "    total_n2_rerank += scores[1]\n",
    "    total_n3_rerank += scores[2]\n",
    "\n",
    "print(f\"Query example: {query}\")\n",
    "print(f\"Reranked items example: {reranked_items}\")\n",
    "print(f\"Scores example: {scores}\")\n",
    "print(f\"Total reranked scores: {total_n1_rerank}, {total_n2_rerank}, {total_n3_rerank}\")\n",
    "\n",
    "avg_n1_rerank = total_n1_rerank / len(results)\n",
    "avg_n2_rerank = total_n2_rerank / len(results)\n",
    "avg_n3_rerank = total_n3_rerank / len(results)\n",
    "\n",
    "print(f\"Average reranked scores: {avg_n1_rerank:.2f}, {avg_n2_rerank:.2f}, {avg_n3_rerank:.2f}\")\n",
    "print(f\"Baseline average scores: {avg_n1:.2f}, {avg_n2:.2f}, {avg_n3:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a53b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
